{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "bfb86d9e-2b00-440a-a9e7-6eb00842c910",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "import torch\n",
    "from torch.utils.data import DataLoader, Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "497324fe-4245-448b-8281-c26f45f3c088",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LaegueDataset_train(Dataset):\n",
    "    def __init__(self ):\n",
    "        dataset_location = open(\"league_ranked_2020_short_for_testing2.json\")\n",
    "        championidtable_location = \"riot_champion.csv\"\n",
    "\n",
    "        self.dataset_train = json.load(dataset_location)\n",
    "\n",
    "        self.championid_to_name = pd.read_csv(championidtable_location)\n",
    "\n",
    "        self.lookuptable = self.championid_to_name[\"key\"].values.tolist()\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.dataset_train[\"data\"])\n",
    "\n",
    "    def __getitem__(self, idx_match):\n",
    "        try:\n",
    "            # Get the Champion keys of every player in one match\n",
    "            data = [self.dataset_train[\"data\"][idx_match][i][\"championId\"] for i in range(10)]\n",
    "\n",
    "            # convert champion keys into index notation\n",
    "            data = torch.tensor([self.lookuptable.index(data[i]) for i in range(10)])\n",
    "\n",
    "            # convert data into one hot vecot encoding\n",
    "            data = torch.eye(148).index_select(dim=0, index=data)\n",
    "            data = data.flatten()\n",
    "\n",
    "            target = torch.tensor([int(self.dataset_train[\"data\"][idx_match][1][\"stats\"][\"win\"]),\n",
    "                                   int(self.dataset_train[\"data\"][idx_match][8][\"stats\"][\"win\"])\n",
    "                                   ])\n",
    "\n",
    "        except Exception as e:\n",
    "            data = self.dataset_train[\"data\"][idx_match]\n",
    "            type__ = type(self.dataset_train[\"data\"][idx_match])\n",
    "            print(f\"An Exception occurred when trying to load the dataset: {e}\")\n",
    "            print(f\"data: {data}\")\n",
    "            print(f\"type of data: {type__}\")\n",
    "            print(f\"index: {idx_match}\")\n",
    "            # print(len(self.dataset_train[\"data\"][idx_match]))\n",
    "\n",
    "            raise Exception\n",
    "\n",
    "            #  Get the Champion keys of every player in one match\n",
    "            data = [self.dataset_train[\"data\"][idx_match + 1][i][\"championId\"] for i in range(10)]\n",
    "\n",
    "            # convert champion keys into ids\n",
    "            data = torch.tensor([self.lookuptable.index(data[i]) for i in range(10)])\n",
    "\n",
    "            # convert it into one hot vector encoding\n",
    "            data = torch.eye(148).index_select(dim=0, index=data)\n",
    "            data = data.flatten()\n",
    "\n",
    "            target = torch.tensor([int(self.dataset_train[\"data\"][idx_match + 1][1][\"stats\"][\"win\"]),\n",
    "                                   int(self.dataset_train[\"data\"][idx_match + 1][8][\"stats\"][\"win\"])\n",
    "                                   ])\n",
    "\n",
    "        return data, target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "4cb1b310-4d70-487d-a4fd-f98240826ccb",
   "metadata": {},
   "outputs": [],
   "source": [
    "traindataset = LaegueDataset_train()\n",
    "train_dataloader = DataLoader(traindataset, batch_size=2, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "908db7a9-2e85-4bc9-8638-5ef8da4bed3b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6\n"
     ]
    }
   ],
   "source": [
    " print(len(train_dataloader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "21833489-b40c-4817-adc5-49dcd9c911f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 1480])\n",
      "torch.Size([2, 2])\n",
      "torch.Size([2, 1480])\n",
      "torch.Size([2, 2])\n",
      "torch.Size([2, 1480])\n",
      "torch.Size([2, 2])\n",
      "torch.Size([2, 1480])\n",
      "torch.Size([2, 2])\n",
      "torch.Size([2, 1480])\n",
      "torch.Size([2, 2])\n",
      "torch.Size([1, 1480])\n",
      "torch.Size([1, 2])\n"
     ]
    }
   ],
   "source": [
    "for data, target in train_dataloader:\n",
    "    print(data.size())\n",
    "    print(target.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "5061a1e1-5c73-4d68-9912-2809a96bc071",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_location = open(\"league_ranked_2020_short_for_testing.json\")\n",
    "championidtable_location = \"riot_champion.csv\"\n",
    "\n",
    "dataset_train = json.load(dataset_location)\n",
    "\n",
    "championid_to_name = pd.read_csv(championidtable_location)\n",
    "\n",
    "lookuptable = championid_to_name[\"key\"].values.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "9680e746-b640-4aa2-acce-c40db81507f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "data1 = [dataset_train[\"data\"][0][i][\"championId\"] for i in range(10)]  \n",
    "data2 = [dataset_train[\"data\"][1][i][\"championId\"] for i in range(10)]  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "5c084ff6-1fa5-4c01-b2c0-cf25c11089a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[26, 91, 30, 164, 145, 523, 7, 3, 104, 62]\n",
      "[4, 89, 41, 21, 154, 39, 421, 81, 69, 26]\n"
     ]
    }
   ],
   "source": [
    "print(data1)\n",
    "print(data2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "3ed5d83b-5a11-469b-9adc-72730b403914",
   "metadata": {},
   "outputs": [],
   "source": [
    "data1 = torch.tensor([lookuptable.index(data1[i]) for i in range(10)]) \n",
    "# convert data into one hot vecot encoding\n",
    "data1 = torch.eye(148).index_select(dim=0, index=data1)\n",
    "\n",
    "data1 = data1.flatten()\n",
    "\n",
    "target1 = torch.tensor([int(dataset_train[\"data\"][0][1][\"stats\"][\"win\"]),\n",
    "                       int(dataset_train[\"data\"][0][8][\"stats\"][\"win\"])\n",
    "                       ])\n",
    "\n",
    "data2 = torch.tensor([lookuptable.index(data2[i]) for i in range(10)]) \n",
    "# convert data into one hot vecot encoding\n",
    "data2 = torch.eye(148).index_select(dim=0, index=data2)\n",
    "\n",
    "data2 = data2.flatten()\n",
    "\n",
    "target2 = torch.tensor([int(dataset_train[\"data\"][0][1][\"stats\"][\"win\"]),\n",
    "                       int(dataset_train[\"data\"][0][8][\"stats\"][\"win\"])\n",
    "                       ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "81e345d4-74a0-4658-9037-5bbe0f323207",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1480])\n",
      "torch.Size([2])\n",
      "torch.Size([1480])\n",
      "torch.Size([2])\n"
     ]
    }
   ],
   "source": [
    "print(data1.size())\n",
    "print(target1.size())\n",
    "print(data2.size())\n",
    "print(target2.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e9af485-56c2-43da-b5ce-582b82c3a58f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
